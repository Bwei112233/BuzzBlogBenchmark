{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRT Request Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionalities\n",
    "- Analysis of RPCs and queries of LRT requests.\n",
    "\n",
    "## Input\n",
    "Log files are read from a directory in `../data`. This directory is assumed to have the following structure:\n",
    "```\n",
    "logs/\n",
    "  [node-1]/\n",
    "    *_service*.tar.gz\n",
    "    ...\n",
    "    apigateway*.tar.gz\n",
    "    ...\n",
    "    loadgen.tar.gz\n",
    "  ...\n",
    "  [node-n]/\n",
    "    *_service*.tar.gz\n",
    "    ...\n",
    "    apigateway*.tar.gz\n",
    "    ...\n",
    "    loadgen.tar.gz\n",
    "```\n",
    "`*_service*.tar.gz` and `apigateway*.tar.gz` tarballs contain RPC log files named `calls.log` and database query log files named `queries.log`. A tarball `loadgen.tar.gz` contains a request log file named `loadgen.log`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENERAL\n",
    "# Name of the directory in `../data`\n",
    "EXPERIMENT_DIRNAME = \"BuzzBlogBenchmark_2021-11-03-23-37-35\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import tarfile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Constants\n",
    "REQUEST_LOG_PATTERN = r\"^\\[(\\d+\\-\\d+\\-\\d+ \\d+:\\d+:\\d+.\\d+)\\] (.+) (.+) (\\d+) - latency=(\\d+.\\d+)$\"\n",
    "URL_PATTERN = r\"^http://[\\w\\.]+:\\d+/{path}/?\\??{qs}$\"\n",
    "REQUEST_TO_TYPE = {\n",
    "    (URL_PATTERN.format(path=\"account/\\d+\", qs=\"\"), \"GET\"): \"retrieve_account\",\n",
    "    (URL_PATTERN.format(path=\"account\", qs=\"\"), \"POST\"): \"create_account\",\n",
    "    (URL_PATTERN.format(path=\"account/\\d+\", qs=\"\"), \"PUT\"): \"update_account\",\n",
    "    (URL_PATTERN.format(path=\"follow\", qs=\"followee_id=\\d+\"), \"GET\"): \"retrieve_account_followers\",\n",
    "    (URL_PATTERN.format(path=\"follow\", qs=\"follower_id=\\d+\"), \"GET\"): \"retrieve_account_followees\",\n",
    "    (URL_PATTERN.format(path=\"follow\", qs=\"\"), \"POST\"): \"follow_account\",\n",
    "    (URL_PATTERN.format(path=\"follow/\\d+\", qs=\"\"), \"DELETE\"): \"delete_follow\",\n",
    "    (URL_PATTERN.format(path=\"like\", qs=\"account_id=\\d+\"), \"GET\"): \"retrieve_account_likes\",\n",
    "    (URL_PATTERN.format(path=\"like\", qs=\"post_id=\\d+\"), \"GET\"): \"retrieve_post_likes\",\n",
    "    (URL_PATTERN.format(path=\"like\", qs=\"\"), \"POST\"): \"like_post\",\n",
    "    (URL_PATTERN.format(path=\"like/\\d+\", qs=\"\"), \"DELETE\"): \"delete_like\",\n",
    "    (URL_PATTERN.format(path=\"post\", qs=\"\"), \"GET\"): \"retrieve_recent_posts\",\n",
    "    (URL_PATTERN.format(path=\"post\", qs=\"author_id=\\d+\"), \"GET\"): \"retrieve_account_posts\",\n",
    "    (URL_PATTERN.format(path=\"post/\\d+\", qs=\"\"), \"GET\"): \"retrieve_post\",\n",
    "    (URL_PATTERN.format(path=\"post\", qs=\"\"), \"POST\"): \"create_post\",\n",
    "    (URL_PATTERN.format(path=\"post/\\d+\", qs=\"\"), \"DELETE\"): \"delete_post\"\n",
    "}\n",
    "COMPONENT_TARBALL_PATTERNS = [\n",
    "    r\"^apigateway.*\\.tar\\.gz$\",\n",
    "    r\"^.+_service.*\\.tar\\.gz$\",\n",
    "]\n",
    "RPC_LOG_PATTERN = r\"^\\[(.+)\\] pid=(.+) tid=(.+) request_id=(.+) server=(.+) function=(.+) latency=(.+)$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Log Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse logs\n",
    "requests = {\"timestamp\": [], \"method\": [], \"url\": [], \"status_code\": [], \"latency\": [], \"request_id\": []}\n",
    "node_names = os.listdir(os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\"))\n",
    "for node_name in node_names:\n",
    "  node_min_timestamp = None\n",
    "  tarball_path = os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\", node_name, \"loadgen.tar.gz\")\n",
    "  if os.path.exists(tarball_path):\n",
    "    with tarfile.open(tarball_path, \"r:gz\") as tar:\n",
    "      for filename in tar.getnames():\n",
    "        if filename.endswith(\"loadgen.log\"):\n",
    "          with tar.extractfile(filename) as requests_log_file:\n",
    "            for log in requests_log_file:\n",
    "              timestamp, method, url, status_code, latency = re.match(REQUEST_LOG_PATTERN, log.decode(\"utf-8\")).groups()\n",
    "              request_id = re.findall(\"request_id=([a-zA-Z0-9]+)&?\", url)[0]\n",
    "              url = re.sub(\"limit=\\d+&?\", \"\", url)\n",
    "              url = re.sub(\"offset=\\d+&?\", \"\", url)\n",
    "              url = re.sub(\"request_id=[a-zA-Z0-9]+&?\", \"\", url)\n",
    "              url = re.sub(\"&$\", \"\", url)\n",
    "              url = re.sub(\"\\?$\", \"\", url)\n",
    "              timestamp = datetime.datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "              if node_min_timestamp is None:\n",
    "                node_min_timestamp = timestamp\n",
    "              requests[\"timestamp\"].append((timestamp - node_min_timestamp).total_seconds())\n",
    "              requests[\"method\"].append(method)\n",
    "              requests[\"url\"].append(url)\n",
    "              requests[\"status_code\"].append(int(status_code))\n",
    "              requests[\"latency\"].append(float(latency))\n",
    "              requests[\"request_id\"].append(request_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "requests = pd.DataFrame.from_dict(requests)\n",
    "requests.sort_values(by=\"timestamp\", ascending=True, inplace=True)\n",
    "requests[\"type\"] = requests.apply(\n",
    "    lambda r: [request_type for ((pattern, method), request_type) in REQUEST_TO_TYPE.items()\n",
    "    if method == r[\"method\"] and re.match(pattern, r[\"url\"])][0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPC Log Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse logs\n",
    "rpc = {\"node_name\": [], \"timestamp\": [], \"request_id\": [], \"server\": [], \"function\": [], \"latency\": []}\n",
    "node_names = os.listdir(os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\"))\n",
    "for node_name in node_names:\n",
    "  for tarball_name in os.listdir(os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\", node_name)):\n",
    "    if sum([1 if re.match(tarball_pattern, tarball_name) else 0 for tarball_pattern in COMPONENT_TARBALL_PATTERNS]):\n",
    "      tarball_path = os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\", node_name, tarball_name)\n",
    "      with tarfile.open(tarball_path, \"r:gz\") as tar:\n",
    "        for filename in tar.getnames():\n",
    "          if filename.endswith(\"calls.log\"):\n",
    "            with tar.extractfile(filename) as log_file:\n",
    "              for row in log_file:\n",
    "                rpc_log_match = re.match(RPC_LOG_PATTERN, row.decode(\"utf-8\"))\n",
    "                if rpc_log_match:\n",
    "                  timestamp, pid, tid, request_id, server, function, latency = rpc_log_match.groups()\n",
    "                  rpc[\"node_name\"].append(node_name)\n",
    "                  rpc[\"timestamp\"].append(datetime.datetime.strptime(timestamp[:-3], \"%H:%M:%S.%f\"))\n",
    "                  rpc[\"request_id\"].append(request_id)\n",
    "                  rpc[\"server\"].append(server)\n",
    "                  rpc[\"function\"].append(function)\n",
    "                  rpc[\"latency\"].append(float(latency) * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "rpc = pd.DataFrame.from_dict(rpc)\n",
    "\n",
    "# Get values\n",
    "function_names = sorted(rpc[\"function\"].unique())\n",
    "min_timestamp = rpc[\"timestamp\"].values.min()\n",
    "\n",
    "# (Re) Build columns\n",
    "rpc[\"timestamp\"] = rpc.apply(lambda r: (r[\"timestamp\"] - min_timestamp).total_seconds(), axis=1)\n",
    "rpc[\"window\"] = rpc.apply(lambda r: int(r[\"timestamp\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of LRT Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of requests with latency over P99.9\n",
    "lrt_requests = requests[(requests[\"latency\"] > requests[requests[\"status_code\"] == 200][\"latency\"].quantile(0.999))]\n",
    "for lrt_request in lrt_requests.to_dict(\"records\"):\n",
    "    print(\"Request ID: %s\" % lrt_request[\"request_id\"])\n",
    "    print(\"  Type: %s\" % lrt_request[\"type\"])\n",
    "    print(\"  RPCs:\")\n",
    "    for lrt_request_rpc in rpc[(rpc[\"request_id\"] == lrt_request[\"request_id\"])].to_dict(\"records\"):\n",
    "        print(\"    %s - %s\" % (lrt_request_rpc[\"function\"], lrt_request_rpc[\"latency\"]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
